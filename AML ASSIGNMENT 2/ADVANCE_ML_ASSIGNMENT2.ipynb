{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "udHDBA5VfZTU",
        "outputId": "e1318dd8-06ad-435c-fa20-19a8d871751b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f03eb869-be9c-4097-93af-31f0a38fe682\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f03eb869-be9c-4097-93af-31f0a38fe682\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (2).json': b'{\"username\":\"lvemavar\",\"key\":\"f4ffd802fe008780668fe22faa542da7\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# To upload the kaggle.json file\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "\n",
        "# Changing the prath to the .kaggle folder\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#  Changing the permissions to perform read and write access\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eMKxntTfxNe",
        "outputId": "fd6e0905-371d-4363-e141-0f8a8fab0bfb"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dogs-vs-cats dataset\n",
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKpEGRx_f31j",
        "outputId": "d6c41af0-f875-43ec-f778-970470cd918f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dogs-vs-cats.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping dogs-vs-cats dataset file\n",
        "!unzip -qq dogs-vs-cats.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht4j1iCiiGm9",
        "outputId": "c2eeff82-28e7-44c9-e30f-82f500122bce"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace sampleSubmission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping train sample\n",
        "!unzip -qq train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjfqfgY0iQzR",
        "outputId": "63bb277a-24e8-4acd-a9ba-645189d3f553"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hylypF5Sk_5W",
        "outputId": "ad7a8656-ae33-4279-cc05-1d44bc398171"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.16)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.34.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.11.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "#shutil.rmtree(\"cats_vs_dogs_small\")\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)\n"
      ],
      "metadata": {
        "id": "z2HclI6QmZSE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the model and running the model summary\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPSfwE1BidU_",
        "outputId": "4ab31cf7-5063-4797-b762-9d59d399505f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_6 (Rescaling)     (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 89, 89, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 43, 43, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 20, 20, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 9, 9, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,041\n",
            "Trainable params: 991,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration of the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "ao4Qp9jcih_B"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaring the image size and batch size to read the images from train. validation and test directories\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C4lZp5Qk4i3",
        "outputId": "e8b20a1e-d595-40d0-f13d-aa3fc9f76270"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFltiAAeklPs",
        "outputId": "629eace3-7449-4a44-9f04-d5187cbce6ea"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 6s 63ms/step - loss: 0.6980 - accuracy: 0.4865 - val_loss: 0.6901 - val_accuracy: 0.5290\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 8s 117ms/step - loss: 0.6940 - accuracy: 0.5425 - val_loss: 0.6876 - val_accuracy: 0.5200\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.6761 - accuracy: 0.5860 - val_loss: 0.6451 - val_accuracy: 0.6260\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.6484 - accuracy: 0.6290 - val_loss: 0.7126 - val_accuracy: 0.5430\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 7s 115ms/step - loss: 0.6133 - accuracy: 0.6730 - val_loss: 0.6514 - val_accuracy: 0.6460\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.5773 - accuracy: 0.7115 - val_loss: 0.6762 - val_accuracy: 0.6330\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.5258 - accuracy: 0.7390 - val_loss: 0.6151 - val_accuracy: 0.6800\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 7s 110ms/step - loss: 0.4996 - accuracy: 0.7620 - val_loss: 0.5533 - val_accuracy: 0.7510\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4430 - accuracy: 0.7855 - val_loss: 0.5627 - val_accuracy: 0.7330\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.3922 - accuracy: 0.8195 - val_loss: 0.6975 - val_accuracy: 0.7240\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3458 - accuracy: 0.8555 - val_loss: 0.9903 - val_accuracy: 0.6930\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2595 - accuracy: 0.8900 - val_loss: 0.7365 - val_accuracy: 0.7280\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.2350 - accuracy: 0.8985 - val_loss: 0.8713 - val_accuracy: 0.7520\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.1823 - accuracy: 0.9295 - val_loss: 1.0398 - val_accuracy: 0.7520\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.1332 - accuracy: 0.9530 - val_loss: 1.0350 - val_accuracy: 0.7360\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1052 - accuracy: 0.9670 - val_loss: 1.7543 - val_accuracy: 0.7130\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0995 - accuracy: 0.9630 - val_loss: 1.2447 - val_accuracy: 0.7390\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.0978 - accuracy: 0.9700 - val_loss: 1.2409 - val_accuracy: 0.7530\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0640 - accuracy: 0.9770 - val_loss: 1.4673 - val_accuracy: 0.7230\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0681 - accuracy: 0.9745 - val_loss: 1.3937 - val_accuracy: 0.7510\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.0335 - accuracy: 0.9860 - val_loss: 1.5657 - val_accuracy: 0.7390\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0655 - accuracy: 0.9815 - val_loss: 1.6739 - val_accuracy: 0.7460\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 6s 98ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 1.6479 - val_accuracy: 0.7280\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 5s 66ms/step - loss: 0.0518 - accuracy: 0.9805 - val_loss: 1.6707 - val_accuracy: 0.7420\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0504 - accuracy: 0.9860 - val_loss: 1.7834 - val_accuracy: 0.7110\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 1.7852 - val_accuracy: 0.7390\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.0437 - accuracy: 0.9865 - val_loss: 1.9761 - val_accuracy: 0.7290\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 2.0302 - val_accuracy: 0.7400\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 7s 103ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 1.9519 - val_accuracy: 0.7370\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0353 - accuracy: 0.9870 - val_loss: 2.2219 - val_accuracy: 0.7310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B19xGhl5oA7i",
        "outputId": "4871b37e-b455-4927-acaa-1afc060e0df7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 66ms/step - loss: 0.5760 - accuracy: 0.7415\n",
            "Test accuracy: 0.742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaring Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "CBbJja6CoIWl"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Building the model and configuing it\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "vAWSoI4coNB3"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex_103LtoQ91",
        "outputId": "87bca76f-a0fd-4179-93ba-1ff005126610"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 11s 120ms/step - loss: 0.7178 - accuracy: 0.4830 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.6945 - accuracy: 0.5190 - val_loss: 0.7650 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.6979 - accuracy: 0.5105 - val_loss: 0.6901 - val_accuracy: 0.5070\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 6s 82ms/step - loss: 0.7013 - accuracy: 0.5495 - val_loss: 0.6768 - val_accuracy: 0.6240\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.6764 - accuracy: 0.5970 - val_loss: 0.6856 - val_accuracy: 0.5740\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.6592 - accuracy: 0.6240 - val_loss: 0.6776 - val_accuracy: 0.6070\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.6498 - accuracy: 0.6335 - val_loss: 0.6527 - val_accuracy: 0.5990\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.6426 - accuracy: 0.6400 - val_loss: 0.6353 - val_accuracy: 0.6310\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.6295 - accuracy: 0.6440 - val_loss: 0.6299 - val_accuracy: 0.6480\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 6s 94ms/step - loss: 0.6171 - accuracy: 0.6715 - val_loss: 0.6307 - val_accuracy: 0.6530\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.6003 - accuracy: 0.6775 - val_loss: 0.6068 - val_accuracy: 0.6800\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.5806 - accuracy: 0.6845 - val_loss: 0.5581 - val_accuracy: 0.7110\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 7s 101ms/step - loss: 0.5637 - accuracy: 0.7030 - val_loss: 0.5739 - val_accuracy: 0.6920\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.5536 - accuracy: 0.7215 - val_loss: 0.5414 - val_accuracy: 0.7270\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.5393 - accuracy: 0.7310 - val_loss: 0.5846 - val_accuracy: 0.6970\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.5373 - accuracy: 0.7335 - val_loss: 0.5199 - val_accuracy: 0.7440\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.5366 - accuracy: 0.7400 - val_loss: 0.5423 - val_accuracy: 0.7320\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.5083 - accuracy: 0.7475 - val_loss: 0.5079 - val_accuracy: 0.7570\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.4852 - accuracy: 0.7665 - val_loss: 0.5464 - val_accuracy: 0.7510\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 7s 100ms/step - loss: 0.5167 - accuracy: 0.7450 - val_loss: 0.5952 - val_accuracy: 0.7560\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4921 - accuracy: 0.7640 - val_loss: 0.5567 - val_accuracy: 0.7540\n",
            "Epoch 22/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4661 - accuracy: 0.7740 - val_loss: 0.5492 - val_accuracy: 0.7430\n",
            "Epoch 23/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.4794 - accuracy: 0.7775 - val_loss: 0.5147 - val_accuracy: 0.7550\n",
            "Epoch 24/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.4653 - accuracy: 0.7850 - val_loss: 0.6660 - val_accuracy: 0.6990\n",
            "Epoch 25/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.4392 - accuracy: 0.7895 - val_loss: 0.4472 - val_accuracy: 0.7930\n",
            "Epoch 26/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.4324 - accuracy: 0.8010 - val_loss: 0.5100 - val_accuracy: 0.7480\n",
            "Epoch 27/100\n",
            "63/63 [==============================] - 6s 83ms/step - loss: 0.4304 - accuracy: 0.8040 - val_loss: 0.4872 - val_accuracy: 0.7660\n",
            "Epoch 28/100\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.4321 - accuracy: 0.8170 - val_loss: 0.5527 - val_accuracy: 0.7520\n",
            "Epoch 29/100\n",
            "63/63 [==============================] - 7s 97ms/step - loss: 0.4130 - accuracy: 0.8140 - val_loss: 0.5505 - val_accuracy: 0.7700\n",
            "Epoch 30/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.4062 - accuracy: 0.8195 - val_loss: 0.5446 - val_accuracy: 0.7390\n",
            "Epoch 31/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.3932 - accuracy: 0.8260 - val_loss: 0.4360 - val_accuracy: 0.8000\n",
            "Epoch 32/100\n",
            "63/63 [==============================] - 7s 98ms/step - loss: 0.4035 - accuracy: 0.8200 - val_loss: 0.4151 - val_accuracy: 0.8180\n",
            "Epoch 33/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.3977 - accuracy: 0.8235 - val_loss: 0.6041 - val_accuracy: 0.7120\n",
            "Epoch 34/100\n",
            "63/63 [==============================] - 6s 98ms/step - loss: 0.3766 - accuracy: 0.8395 - val_loss: 0.5347 - val_accuracy: 0.7840\n",
            "Epoch 35/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.3514 - accuracy: 0.8440 - val_loss: 0.4586 - val_accuracy: 0.8200\n",
            "Epoch 36/100\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.3472 - accuracy: 0.8480 - val_loss: 0.4639 - val_accuracy: 0.8030\n",
            "Epoch 37/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3474 - accuracy: 0.8515 - val_loss: 0.4749 - val_accuracy: 0.8130\n",
            "Epoch 38/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.3224 - accuracy: 0.8575 - val_loss: 0.9976 - val_accuracy: 0.7040\n",
            "Epoch 39/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.3303 - accuracy: 0.8625 - val_loss: 0.5412 - val_accuracy: 0.8030\n",
            "Epoch 40/100\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3207 - accuracy: 0.8610 - val_loss: 0.5769 - val_accuracy: 0.7750\n",
            "Epoch 41/100\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.3335 - accuracy: 0.8555 - val_loss: 0.4628 - val_accuracy: 0.8060\n",
            "Epoch 42/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.3007 - accuracy: 0.8650 - val_loss: 0.5559 - val_accuracy: 0.8110\n",
            "Epoch 43/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.3230 - accuracy: 0.8625 - val_loss: 0.5192 - val_accuracy: 0.8040\n",
            "Epoch 44/100\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.3089 - accuracy: 0.8615 - val_loss: 0.4798 - val_accuracy: 0.8350\n",
            "Epoch 45/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2979 - accuracy: 0.8790 - val_loss: 0.5123 - val_accuracy: 0.8020\n",
            "Epoch 46/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.2799 - accuracy: 0.8765 - val_loss: 0.5030 - val_accuracy: 0.7970\n",
            "Epoch 47/100\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 0.2579 - accuracy: 0.8920 - val_loss: 0.6881 - val_accuracy: 0.8180\n",
            "Epoch 48/100\n",
            "63/63 [==============================] - 5s 73ms/step - loss: 0.2938 - accuracy: 0.8780 - val_loss: 0.5911 - val_accuracy: 0.8050\n",
            "Epoch 49/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.2713 - accuracy: 0.8915 - val_loss: 0.6115 - val_accuracy: 0.8040\n",
            "Epoch 50/100\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.2695 - accuracy: 0.8835 - val_loss: 0.5209 - val_accuracy: 0.8130\n",
            "Epoch 51/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2699 - accuracy: 0.8795 - val_loss: 0.5183 - val_accuracy: 0.8070\n",
            "Epoch 52/100\n",
            "63/63 [==============================] - 6s 85ms/step - loss: 0.2508 - accuracy: 0.8930 - val_loss: 0.6337 - val_accuracy: 0.8220\n",
            "Epoch 53/100\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.2681 - accuracy: 0.8965 - val_loss: 0.4636 - val_accuracy: 0.8300\n",
            "Epoch 54/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.2431 - accuracy: 0.9035 - val_loss: 0.5986 - val_accuracy: 0.8180\n",
            "Epoch 55/100\n",
            "63/63 [==============================] - 8s 115ms/step - loss: 0.2427 - accuracy: 0.9010 - val_loss: 0.4967 - val_accuracy: 0.8330\n",
            "Epoch 56/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2394 - accuracy: 0.9015 - val_loss: 0.6458 - val_accuracy: 0.8140\n",
            "Epoch 57/100\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2118 - accuracy: 0.9165 - val_loss: 0.6029 - val_accuracy: 0.8220\n",
            "Epoch 58/100\n",
            "63/63 [==============================] - 6s 91ms/step - loss: 0.2536 - accuracy: 0.8995 - val_loss: 0.5512 - val_accuracy: 0.8420\n",
            "Epoch 59/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.2254 - accuracy: 0.9180 - val_loss: 0.5549 - val_accuracy: 0.8270\n",
            "Epoch 60/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2295 - accuracy: 0.9110 - val_loss: 0.6212 - val_accuracy: 0.8250\n",
            "Epoch 61/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.2113 - accuracy: 0.9055 - val_loss: 0.7858 - val_accuracy: 0.8070\n",
            "Epoch 62/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.2325 - accuracy: 0.9115 - val_loss: 0.6724 - val_accuracy: 0.8100\n",
            "Epoch 63/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.2009 - accuracy: 0.9245 - val_loss: 0.5816 - val_accuracy: 0.8040\n",
            "Epoch 64/100\n",
            "63/63 [==============================] - 5s 84ms/step - loss: 0.2045 - accuracy: 0.9145 - val_loss: 0.5221 - val_accuracy: 0.8300\n",
            "Epoch 65/100\n",
            "63/63 [==============================] - 6s 84ms/step - loss: 0.2088 - accuracy: 0.9190 - val_loss: 0.5944 - val_accuracy: 0.8180\n",
            "Epoch 66/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1906 - accuracy: 0.9190 - val_loss: 0.7375 - val_accuracy: 0.8040\n",
            "Epoch 67/100\n",
            "63/63 [==============================] - 6s 85ms/step - loss: 0.2071 - accuracy: 0.9190 - val_loss: 0.6125 - val_accuracy: 0.8280\n",
            "Epoch 68/100\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.2126 - accuracy: 0.9105 - val_loss: 1.2919 - val_accuracy: 0.7160\n",
            "Epoch 69/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1921 - accuracy: 0.9275 - val_loss: 0.5100 - val_accuracy: 0.8530\n",
            "Epoch 70/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1989 - accuracy: 0.9230 - val_loss: 0.5950 - val_accuracy: 0.8170\n",
            "Epoch 71/100\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.1669 - accuracy: 0.9295 - val_loss: 0.6892 - val_accuracy: 0.8350\n",
            "Epoch 72/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1788 - accuracy: 0.9340 - val_loss: 0.6724 - val_accuracy: 0.8300\n",
            "Epoch 73/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.1787 - accuracy: 0.9250 - val_loss: 0.5726 - val_accuracy: 0.8490\n",
            "Epoch 74/100\n",
            "63/63 [==============================] - 6s 90ms/step - loss: 0.1934 - accuracy: 0.9285 - val_loss: 0.7347 - val_accuracy: 0.8180\n",
            "Epoch 75/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.1956 - accuracy: 0.9225 - val_loss: 0.5319 - val_accuracy: 0.8100\n",
            "Epoch 76/100\n",
            "63/63 [==============================] - 5s 70ms/step - loss: 0.1676 - accuracy: 0.9335 - val_loss: 0.5398 - val_accuracy: 0.8430\n",
            "Epoch 77/100\n",
            "63/63 [==============================] - 7s 96ms/step - loss: 0.1836 - accuracy: 0.9275 - val_loss: 0.6501 - val_accuracy: 0.8420\n",
            "Epoch 78/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1836 - accuracy: 0.9330 - val_loss: 0.5650 - val_accuracy: 0.8350\n",
            "Epoch 79/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1693 - accuracy: 0.9345 - val_loss: 0.7593 - val_accuracy: 0.8310\n",
            "Epoch 80/100\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.1744 - accuracy: 0.9365 - val_loss: 0.6183 - val_accuracy: 0.8480\n",
            "Epoch 81/100\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1593 - accuracy: 0.9345 - val_loss: 0.6568 - val_accuracy: 0.8300\n",
            "Epoch 82/100\n",
            "63/63 [==============================] - 5s 70ms/step - loss: 0.1646 - accuracy: 0.9410 - val_loss: 0.6925 - val_accuracy: 0.8270\n",
            "Epoch 83/100\n",
            "63/63 [==============================] - 8s 118ms/step - loss: 0.1710 - accuracy: 0.9390 - val_loss: 0.6412 - val_accuracy: 0.8370\n",
            "Epoch 84/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.1730 - accuracy: 0.9435 - val_loss: 0.9884 - val_accuracy: 0.8310\n",
            "Epoch 85/100\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1673 - accuracy: 0.9385 - val_loss: 0.6801 - val_accuracy: 0.8160\n",
            "Epoch 86/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1511 - accuracy: 0.9450 - val_loss: 0.6506 - val_accuracy: 0.8550\n",
            "Epoch 87/100\n",
            "63/63 [==============================] - 5s 68ms/step - loss: 0.1937 - accuracy: 0.9375 - val_loss: 0.5703 - val_accuracy: 0.8560\n",
            "Epoch 88/100\n",
            "63/63 [==============================] - 8s 119ms/step - loss: 0.1660 - accuracy: 0.9415 - val_loss: 0.7759 - val_accuracy: 0.8040\n",
            "Epoch 89/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.1722 - accuracy: 0.9375 - val_loss: 0.7505 - val_accuracy: 0.8400\n",
            "Epoch 90/100\n",
            "63/63 [==============================] - 5s 84ms/step - loss: 0.1797 - accuracy: 0.9370 - val_loss: 0.6709 - val_accuracy: 0.8410\n",
            "Epoch 91/100\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.1563 - accuracy: 0.9455 - val_loss: 0.6679 - val_accuracy: 0.8540\n",
            "Epoch 92/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1371 - accuracy: 0.9525 - val_loss: 0.5761 - val_accuracy: 0.8630\n",
            "Epoch 93/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.1746 - accuracy: 0.9415 - val_loss: 0.5815 - val_accuracy: 0.8560\n",
            "Epoch 94/100\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.1656 - accuracy: 0.9385 - val_loss: 0.9170 - val_accuracy: 0.8200\n",
            "Epoch 95/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1282 - accuracy: 0.9500 - val_loss: 1.0012 - val_accuracy: 0.8350\n",
            "Epoch 96/100\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.1716 - accuracy: 0.9380 - val_loss: 1.1537 - val_accuracy: 0.7750\n",
            "Epoch 97/100\n",
            "63/63 [==============================] - 7s 103ms/step - loss: 0.1660 - accuracy: 0.9415 - val_loss: 0.6750 - val_accuracy: 0.8540\n",
            "Epoch 98/100\n",
            "63/63 [==============================] - 5s 68ms/step - loss: 0.1616 - accuracy: 0.9465 - val_loss: 0.6495 - val_accuracy: 0.8550\n",
            "Epoch 99/100\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1499 - accuracy: 0.9510 - val_loss: 0.6552 - val_accuracy: 0.8390\n",
            "Epoch 100/100\n",
            "63/63 [==============================] - 6s 87ms/step - loss: 0.1734 - accuracy: 0.9405 - val_loss: 0.6855 - val_accuracy: 0.8450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2orTyLHqzNB",
        "outputId": "721273c4-95d6-47a2-9371-858451186782"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 66ms/step - loss: 0.4408 - accuracy: 0.8040\n",
            "Test accuracy: 0.804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 1000 to 2000\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "shutil.rmtree(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_IncreasedTrainSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 2000 samples, test has 1000 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=2000)\n",
        "make_subset(\"validation\", start_index=2000, end_index=2500)\n",
        "make_subset(\"test\", start_index=2500, end_index=3500)"
      ],
      "metadata": {
        "id": "J6h34ZuDq6N8"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "KDDxVnMUtKS7"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "M7lvWDm1rxFJ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history= model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ukBjbwsYAC",
        "outputId": "8ee4a3c5-2eb8-4b26-9933-33eba9eb6ac1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - 6s 61ms/step - loss: 0.7100 - accuracy: 0.5265 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - 6s 100ms/step - loss: 0.6937 - accuracy: 0.5500 - val_loss: 0.6867 - val_accuracy: 0.5330\n",
            "Epoch 3/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.6791 - accuracy: 0.5850 - val_loss: 0.6669 - val_accuracy: 0.5930\n",
            "Epoch 4/30\n",
            "63/63 [==============================] - 6s 85ms/step - loss: 0.6483 - accuracy: 0.6245 - val_loss: 0.6053 - val_accuracy: 0.6680\n",
            "Epoch 5/30\n",
            "63/63 [==============================] - 6s 85ms/step - loss: 0.6083 - accuracy: 0.6635 - val_loss: 0.9507 - val_accuracy: 0.5580\n",
            "Epoch 6/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5924 - accuracy: 0.6940 - val_loss: 0.6586 - val_accuracy: 0.6560\n",
            "Epoch 7/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.5555 - accuracy: 0.7170 - val_loss: 0.5884 - val_accuracy: 0.6890\n",
            "Epoch 8/30\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.5221 - accuracy: 0.7415 - val_loss: 0.6668 - val_accuracy: 0.7060\n",
            "Epoch 9/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4880 - accuracy: 0.7520 - val_loss: 0.5452 - val_accuracy: 0.7230\n",
            "Epoch 10/30\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.4460 - accuracy: 0.7810 - val_loss: 0.6066 - val_accuracy: 0.7150\n",
            "Epoch 11/30\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.4031 - accuracy: 0.8160 - val_loss: 0.5885 - val_accuracy: 0.7190\n",
            "Epoch 12/30\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.3640 - accuracy: 0.8375 - val_loss: 0.6028 - val_accuracy: 0.7300\n",
            "Epoch 13/30\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.3175 - accuracy: 0.8660 - val_loss: 0.6412 - val_accuracy: 0.7380\n",
            "Epoch 14/30\n",
            "63/63 [==============================] - 6s 85ms/step - loss: 0.2689 - accuracy: 0.8860 - val_loss: 0.8291 - val_accuracy: 0.7030\n",
            "Epoch 15/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2279 - accuracy: 0.9080 - val_loss: 0.8912 - val_accuracy: 0.6570\n",
            "Epoch 16/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1768 - accuracy: 0.9355 - val_loss: 0.9041 - val_accuracy: 0.7220\n",
            "Epoch 17/30\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.1600 - accuracy: 0.9400 - val_loss: 1.2939 - val_accuracy: 0.6750\n",
            "Epoch 18/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1235 - accuracy: 0.9525 - val_loss: 1.1158 - val_accuracy: 0.7170\n",
            "Epoch 19/30\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.0910 - accuracy: 0.9655 - val_loss: 1.2291 - val_accuracy: 0.7170\n",
            "Epoch 20/30\n",
            "63/63 [==============================] - 6s 89ms/step - loss: 0.1222 - accuracy: 0.9590 - val_loss: 1.1519 - val_accuracy: 0.7390\n",
            "Epoch 21/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0722 - accuracy: 0.9725 - val_loss: 1.3572 - val_accuracy: 0.7260\n",
            "Epoch 22/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0571 - accuracy: 0.9835 - val_loss: 1.3930 - val_accuracy: 0.7370\n",
            "Epoch 23/30\n",
            "63/63 [==============================] - 8s 116ms/step - loss: 0.0693 - accuracy: 0.9835 - val_loss: 1.5496 - val_accuracy: 0.7220\n",
            "Epoch 24/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0678 - accuracy: 0.9805 - val_loss: 1.9891 - val_accuracy: 0.7070\n",
            "Epoch 25/30\n",
            "63/63 [==============================] - 5s 71ms/step - loss: 0.0579 - accuracy: 0.9820 - val_loss: 1.5153 - val_accuracy: 0.7360\n",
            "Epoch 26/30\n",
            "63/63 [==============================] - 6s 92ms/step - loss: 0.0445 - accuracy: 0.9825 - val_loss: 1.9809 - val_accuracy: 0.7340\n",
            "Epoch 27/30\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.0486 - accuracy: 0.9870 - val_loss: 2.0420 - val_accuracy: 0.6970\n",
            "Epoch 28/30\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0470 - accuracy: 0.9840 - val_loss: 2.1656 - val_accuracy: 0.7000\n",
            "Epoch 29/30\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.0718 - accuracy: 0.9745 - val_loss: 1.9098 - val_accuracy: 0.7100\n",
            "Epoch 30/30\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0362 - accuracy: 0.9855 - val_loss: 2.1662 - val_accuracy: 0.7160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUEMqm_s5wXP",
        "outputId": "7b88c07c-0678-4938-8717-8f7d5320ae03"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 3s 38ms/step - loss: 0.5660 - accuracy: 0.7120\n",
            "Test accuracy: 0.712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "# Increasing the training sample from 1000 to 2000\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_OptimalTrainSamples1\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 1000 samples, and validation has 500 samples\n",
        "# make_subset(\"train\", start_index=0, end_index=3500)\n",
        "# make_subset(\"validation\", start_index=2500, end_index=3000)\n",
        "# make_subset(\"test\", start_index=3000, end_index=4000)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "bjJPEeOE53zM"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "vV46CYmk57nz"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ael6jHA96Axu"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Train the model with varying training sample sizes\n",
        "sample_sizes = [3500,4000,4500,5000]\n",
        "history_dict = []\n",
        "for size in sample_sizes:\n",
        "    # Set up the training subset\n",
        "    make_subset(\"temp_train\", start_index=1500, end_index=size)\n",
        "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
        "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
        "    train_dataset = image_dataset_from_directory(\n",
        "      new_base_dir / \"temp_train\",\n",
        "      image_size=(180, 180),\n",
        "      batch_size=20)\n",
        "    # Using the callbacks function to monitor validation loss and running the model\n",
        "\n",
        "    callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")]\n",
        "\n",
        "    history = model.fit(\n",
        "      train_dataset,\n",
        "      epochs=30,\n",
        "      validation_data=validation_dataset,\n",
        "      callbacks=callbacks)\n",
        "\n",
        "    test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "    test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "    history_dict.append(test_acc)\n",
        "    print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4NxhVm86He1",
        "outputId": "2918df7a-05cc-46d5-e005-2205f14e43e3"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 32s 53ms/step - loss: 0.7089 - accuracy: 0.5275 - val_loss: 0.6772 - val_accuracy: 0.6020\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 11s 52ms/step - loss: 0.6686 - accuracy: 0.5990 - val_loss: 0.6124 - val_accuracy: 0.6720\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.6362 - accuracy: 0.6530 - val_loss: 0.5856 - val_accuracy: 0.7040\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.5618 - accuracy: 0.7153 - val_loss: 0.5266 - val_accuracy: 0.7440\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.5267 - accuracy: 0.7375 - val_loss: 0.5355 - val_accuracy: 0.7050\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.4819 - accuracy: 0.7735 - val_loss: 0.4794 - val_accuracy: 0.7710\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.4431 - accuracy: 0.7885 - val_loss: 0.5835 - val_accuracy: 0.7080\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 10s 50ms/step - loss: 0.3873 - accuracy: 0.8267 - val_loss: 0.5588 - val_accuracy: 0.7650\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.3304 - accuracy: 0.8565 - val_loss: 0.8609 - val_accuracy: 0.7100\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.2700 - accuracy: 0.8885 - val_loss: 0.6332 - val_accuracy: 0.7640\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.2158 - accuracy: 0.9133 - val_loss: 0.6389 - val_accuracy: 0.7680\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1671 - accuracy: 0.9330 - val_loss: 0.7769 - val_accuracy: 0.7390\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 11s 53ms/step - loss: 0.1252 - accuracy: 0.9525 - val_loss: 1.1253 - val_accuracy: 0.7420\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.1027 - accuracy: 0.9603 - val_loss: 1.0310 - val_accuracy: 0.7560\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 11s 52ms/step - loss: 0.0906 - accuracy: 0.9685 - val_loss: 1.1112 - val_accuracy: 0.7580\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 1.0478 - val_accuracy: 0.7840\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 11s 52ms/step - loss: 0.0715 - accuracy: 0.9755 - val_loss: 1.2328 - val_accuracy: 0.7860\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 8s 39ms/step - loss: 0.0697 - accuracy: 0.9768 - val_loss: 1.5950 - val_accuracy: 0.7540\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - 9s 46ms/step - loss: 0.0946 - accuracy: 0.9765 - val_loss: 1.4145 - val_accuracy: 0.7710\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0628 - accuracy: 0.9758 - val_loss: 1.3984 - val_accuracy: 0.7800\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0627 - accuracy: 0.9827 - val_loss: 1.7141 - val_accuracy: 0.7410\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0727 - accuracy: 0.9797 - val_loss: 1.4403 - val_accuracy: 0.7820\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 10s 52ms/step - loss: 0.0636 - accuracy: 0.9805 - val_loss: 1.9476 - val_accuracy: 0.7550\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 11s 52ms/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 1.6412 - val_accuracy: 0.7490\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - 7s 35ms/step - loss: 0.0484 - accuracy: 0.9847 - val_loss: 1.6518 - val_accuracy: 0.7690\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 11s 52ms/step - loss: 0.0512 - accuracy: 0.9855 - val_loss: 1.8513 - val_accuracy: 0.7720\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 8s 40ms/step - loss: 0.0557 - accuracy: 0.9872 - val_loss: 2.2821 - val_accuracy: 0.7630\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 10s 51ms/step - loss: 0.0521 - accuracy: 0.9870 - val_loss: 1.7982 - val_accuracy: 0.7800\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 7s 34ms/step - loss: 0.0507 - accuracy: 0.9875 - val_loss: 2.0757 - val_accuracy: 0.7640\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 11s 56ms/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 2.1134 - val_accuracy: 0.7670\n",
            "63/63 [==============================] - 3s 35ms/step - loss: 0.3981 - accuracy: 0.8235\n",
            "Test accuracy: 0.823\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.3018 - accuracy: 0.9246 - val_loss: 0.6399 - val_accuracy: 0.7770\n",
            "Epoch 2/30\n",
            "250/250 [==============================] - 8s 33ms/step - loss: 0.1073 - accuracy: 0.9630 - val_loss: 1.1137 - val_accuracy: 0.7430\n",
            "Epoch 3/30\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.0650 - accuracy: 0.9784 - val_loss: 1.3695 - val_accuracy: 0.7850\n",
            "Epoch 4/30\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 0.0745 - accuracy: 0.9776 - val_loss: 1.3164 - val_accuracy: 0.7590\n",
            "Epoch 5/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0523 - accuracy: 0.9832 - val_loss: 1.7529 - val_accuracy: 0.7830\n",
            "Epoch 6/30\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 0.0578 - accuracy: 0.9826 - val_loss: 1.7732 - val_accuracy: 0.7600\n",
            "Epoch 7/30\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0525 - accuracy: 0.9850 - val_loss: 1.7276 - val_accuracy: 0.7850\n",
            "Epoch 8/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0589 - accuracy: 0.9854 - val_loss: 2.1365 - val_accuracy: 0.7910\n",
            "Epoch 9/30\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0565 - accuracy: 0.9862 - val_loss: 2.0311 - val_accuracy: 0.8050\n",
            "Epoch 10/30\n",
            "250/250 [==============================] - 9s 33ms/step - loss: 0.0766 - accuracy: 0.9806 - val_loss: 2.2486 - val_accuracy: 0.7930\n",
            "Epoch 11/30\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0749 - accuracy: 0.9852 - val_loss: 2.1290 - val_accuracy: 0.7770\n",
            "Epoch 12/30\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.0657 - accuracy: 0.9830 - val_loss: 2.7480 - val_accuracy: 0.7790\n",
            "Epoch 13/30\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 0.0559 - accuracy: 0.9880 - val_loss: 3.0035 - val_accuracy: 0.8070\n",
            "Epoch 14/30\n",
            "250/250 [==============================] - 12s 45ms/step - loss: 0.0809 - accuracy: 0.9838 - val_loss: 2.6563 - val_accuracy: 0.7790\n",
            "Epoch 15/30\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0632 - accuracy: 0.9860 - val_loss: 2.9658 - val_accuracy: 0.7890\n",
            "Epoch 16/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0660 - accuracy: 0.9868 - val_loss: 2.5487 - val_accuracy: 0.7880\n",
            "Epoch 17/30\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 0.0611 - accuracy: 0.9864 - val_loss: 3.2238 - val_accuracy: 0.7840\n",
            "Epoch 18/30\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 0.0764 - accuracy: 0.9876 - val_loss: 2.9771 - val_accuracy: 0.7750\n",
            "Epoch 19/30\n",
            "250/250 [==============================] - 11s 41ms/step - loss: 0.0576 - accuracy: 0.9886 - val_loss: 3.9106 - val_accuracy: 0.7510\n",
            "Epoch 20/30\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0562 - accuracy: 0.9914 - val_loss: 3.3057 - val_accuracy: 0.7820\n",
            "Epoch 21/30\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.0846 - accuracy: 0.9858 - val_loss: 2.6500 - val_accuracy: 0.7750\n",
            "Epoch 22/30\n",
            "250/250 [==============================] - 8s 33ms/step - loss: 0.0671 - accuracy: 0.9868 - val_loss: 3.4512 - val_accuracy: 0.7740\n",
            "Epoch 23/30\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.0702 - accuracy: 0.9888 - val_loss: 3.1724 - val_accuracy: 0.7810\n",
            "Epoch 24/30\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0700 - accuracy: 0.9882 - val_loss: 3.9825 - val_accuracy: 0.7710\n",
            "Epoch 25/30\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 0.0568 - accuracy: 0.9898 - val_loss: 4.0738 - val_accuracy: 0.7780\n",
            "Epoch 26/30\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 0.0781 - accuracy: 0.9878 - val_loss: 5.0550 - val_accuracy: 0.7520\n",
            "Epoch 27/30\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0736 - accuracy: 0.9860 - val_loss: 4.7914 - val_accuracy: 0.7650\n",
            "Epoch 28/30\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.1059 - accuracy: 0.9862 - val_loss: 4.4298 - val_accuracy: 0.7700\n",
            "Epoch 29/30\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 0.0445 - accuracy: 0.9930 - val_loss: 5.4084 - val_accuracy: 0.7850\n",
            "Epoch 30/30\n",
            "250/250 [==============================] - 8s 33ms/step - loss: 0.0782 - accuracy: 0.9882 - val_loss: 4.0541 - val_accuracy: 0.7790\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.0463 - accuracy: 0.9890\n",
            "Test accuracy: 0.989\n",
            "Found 6000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "300/300 [==============================] - 10s 34ms/step - loss: 0.4100 - accuracy: 0.9317 - val_loss: 0.8430 - val_accuracy: 0.7760\n",
            "Epoch 2/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.1239 - accuracy: 0.9655 - val_loss: 1.1027 - val_accuracy: 0.8080\n",
            "Epoch 3/30\n",
            "300/300 [==============================] - 12s 38ms/step - loss: 0.0709 - accuracy: 0.9780 - val_loss: 1.3867 - val_accuracy: 0.7920\n",
            "Epoch 4/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.0730 - accuracy: 0.9807 - val_loss: 2.2247 - val_accuracy: 0.7600\n",
            "Epoch 5/30\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.0666 - accuracy: 0.9843 - val_loss: 2.7855 - val_accuracy: 0.7590\n",
            "Epoch 6/30\n",
            "300/300 [==============================] - 11s 36ms/step - loss: 0.0796 - accuracy: 0.9848 - val_loss: 2.8756 - val_accuracy: 0.7790\n",
            "Epoch 7/30\n",
            "300/300 [==============================] - 13s 42ms/step - loss: 0.0655 - accuracy: 0.9862 - val_loss: 2.7392 - val_accuracy: 0.7810\n",
            "Epoch 8/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.0951 - accuracy: 0.9827 - val_loss: 3.2100 - val_accuracy: 0.7870\n",
            "Epoch 9/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.0972 - accuracy: 0.9850 - val_loss: 3.1826 - val_accuracy: 0.7680\n",
            "Epoch 10/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.1083 - accuracy: 0.9857 - val_loss: 2.8340 - val_accuracy: 0.8010\n",
            "Epoch 11/30\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.0860 - accuracy: 0.9842 - val_loss: 3.1816 - val_accuracy: 0.7790\n",
            "Epoch 12/30\n",
            "300/300 [==============================] - 13s 44ms/step - loss: 0.0881 - accuracy: 0.9877 - val_loss: 4.4680 - val_accuracy: 0.8010\n",
            "Epoch 13/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.0973 - accuracy: 0.9858 - val_loss: 3.8783 - val_accuracy: 0.7780\n",
            "Epoch 14/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.0808 - accuracy: 0.9905 - val_loss: 4.4053 - val_accuracy: 0.7760\n",
            "Epoch 15/30\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.0621 - accuracy: 0.9898 - val_loss: 4.6653 - val_accuracy: 0.7860\n",
            "Epoch 16/30\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.0913 - accuracy: 0.9878 - val_loss: 4.8312 - val_accuracy: 0.7940\n",
            "Epoch 17/30\n",
            "300/300 [==============================] - 14s 46ms/step - loss: 0.0806 - accuracy: 0.9907 - val_loss: 4.8145 - val_accuracy: 0.7750\n",
            "Epoch 18/30\n",
            "300/300 [==============================] - 12s 41ms/step - loss: 0.0962 - accuracy: 0.9878 - val_loss: 4.6655 - val_accuracy: 0.7910\n",
            "Epoch 19/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.1046 - accuracy: 0.9893 - val_loss: 4.6031 - val_accuracy: 0.8180\n",
            "Epoch 20/30\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.1003 - accuracy: 0.9877 - val_loss: 3.8765 - val_accuracy: 0.7740\n",
            "Epoch 21/30\n",
            "300/300 [==============================] - 11s 36ms/step - loss: 0.0820 - accuracy: 0.9885 - val_loss: 4.7104 - val_accuracy: 0.7780\n",
            "Epoch 22/30\n",
            "300/300 [==============================] - 13s 44ms/step - loss: 0.0687 - accuracy: 0.9908 - val_loss: 6.5375 - val_accuracy: 0.7570\n",
            "Epoch 23/30\n",
            "300/300 [==============================] - 10s 33ms/step - loss: 0.0759 - accuracy: 0.9920 - val_loss: 5.4274 - val_accuracy: 0.7630\n",
            "Epoch 24/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.0854 - accuracy: 0.9905 - val_loss: 7.7538 - val_accuracy: 0.7520\n",
            "Epoch 25/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.1195 - accuracy: 0.9900 - val_loss: 6.7222 - val_accuracy: 0.7700\n",
            "Epoch 26/30\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.0897 - accuracy: 0.9915 - val_loss: 6.2628 - val_accuracy: 0.7940\n",
            "Epoch 27/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.1000 - accuracy: 0.9897 - val_loss: 6.5538 - val_accuracy: 0.7950\n",
            "Epoch 28/30\n",
            "300/300 [==============================] - 12s 41ms/step - loss: 0.0892 - accuracy: 0.9900 - val_loss: 5.7135 - val_accuracy: 0.7990\n",
            "Epoch 29/30\n",
            "300/300 [==============================] - 14s 45ms/step - loss: 0.0774 - accuracy: 0.9913 - val_loss: 6.1845 - val_accuracy: 0.7830\n",
            "Epoch 30/30\n",
            "300/300 [==============================] - 12s 41ms/step - loss: 0.0961 - accuracy: 0.9895 - val_loss: 7.0341 - val_accuracy: 0.7780\n",
            "63/63 [==============================] - 4s 47ms/step - loss: 0.0691 - accuracy: 0.9730\n",
            "Test accuracy: 0.973\n",
            "Found 7000 files belonging to 2 classes.\n",
            "Epoch 1/30\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 0.5549 - accuracy: 0.9366 - val_loss: 1.2768 - val_accuracy: 0.7880\n",
            "Epoch 2/30\n",
            "350/350 [==============================] - 14s 40ms/step - loss: 0.1507 - accuracy: 0.9663 - val_loss: 1.6826 - val_accuracy: 0.7900\n",
            "Epoch 3/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.0967 - accuracy: 0.9813 - val_loss: 2.0421 - val_accuracy: 0.7910\n",
            "Epoch 4/30\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.0966 - accuracy: 0.9816 - val_loss: 2.4195 - val_accuracy: 0.7750\n",
            "Epoch 5/30\n",
            "350/350 [==============================] - 13s 38ms/step - loss: 0.1036 - accuracy: 0.9819 - val_loss: 3.4205 - val_accuracy: 0.7810\n",
            "Epoch 6/30\n",
            "350/350 [==============================] - 15s 44ms/step - loss: 0.1022 - accuracy: 0.9853 - val_loss: 3.5137 - val_accuracy: 0.8020\n",
            "Epoch 7/30\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.0862 - accuracy: 0.9869 - val_loss: 3.9431 - val_accuracy: 0.7440\n",
            "Epoch 8/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1254 - accuracy: 0.9847 - val_loss: 3.4495 - val_accuracy: 0.7880\n",
            "Epoch 9/30\n",
            "350/350 [==============================] - 13s 38ms/step - loss: 0.0948 - accuracy: 0.9880 - val_loss: 3.5318 - val_accuracy: 0.7960\n",
            "Epoch 10/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.0881 - accuracy: 0.9891 - val_loss: 4.1917 - val_accuracy: 0.7930\n",
            "Epoch 11/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.0943 - accuracy: 0.9886 - val_loss: 4.8918 - val_accuracy: 0.7920\n",
            "Epoch 12/30\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.0881 - accuracy: 0.9896 - val_loss: 4.7161 - val_accuracy: 0.8220\n",
            "Epoch 13/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1074 - accuracy: 0.9880 - val_loss: 4.3285 - val_accuracy: 0.7810\n",
            "Epoch 14/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1312 - accuracy: 0.9884 - val_loss: 4.9287 - val_accuracy: 0.8130\n",
            "Epoch 15/30\n",
            "350/350 [==============================] - 15s 41ms/step - loss: 0.1328 - accuracy: 0.9870 - val_loss: 5.3703 - val_accuracy: 0.7710\n",
            "Epoch 16/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1149 - accuracy: 0.9884 - val_loss: 4.6607 - val_accuracy: 0.8110\n",
            "Epoch 17/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.0859 - accuracy: 0.9900 - val_loss: 5.1669 - val_accuracy: 0.7950\n",
            "Epoch 18/30\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.0908 - accuracy: 0.9894 - val_loss: 5.5930 - val_accuracy: 0.7890\n",
            "Epoch 19/30\n",
            "350/350 [==============================] - 13s 37ms/step - loss: 0.1300 - accuracy: 0.9890 - val_loss: 5.3958 - val_accuracy: 0.7770\n",
            "Epoch 20/30\n",
            "350/350 [==============================] - 14s 38ms/step - loss: 0.1329 - accuracy: 0.9886 - val_loss: 6.3510 - val_accuracy: 0.7980\n",
            "Epoch 21/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.1239 - accuracy: 0.9887 - val_loss: 5.8209 - val_accuracy: 0.7960\n",
            "Epoch 22/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.1101 - accuracy: 0.9913 - val_loss: 5.8592 - val_accuracy: 0.7700\n",
            "Epoch 23/30\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.1086 - accuracy: 0.9906 - val_loss: 5.8160 - val_accuracy: 0.7990\n",
            "Epoch 24/30\n",
            "350/350 [==============================] - 14s 38ms/step - loss: 0.0988 - accuracy: 0.9914 - val_loss: 8.7808 - val_accuracy: 0.7980\n",
            "Epoch 25/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.1289 - accuracy: 0.9904 - val_loss: 8.1487 - val_accuracy: 0.8110\n",
            "Epoch 26/30\n",
            "350/350 [==============================] - 15s 41ms/step - loss: 0.1340 - accuracy: 0.9910 - val_loss: 7.3421 - val_accuracy: 0.8080\n",
            "Epoch 27/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.1237 - accuracy: 0.9909 - val_loss: 10.5389 - val_accuracy: 0.7660\n",
            "Epoch 28/30\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.1392 - accuracy: 0.9893 - val_loss: 10.6799 - val_accuracy: 0.7910\n",
            "Epoch 29/30\n",
            "350/350 [==============================] - 13s 36ms/step - loss: 0.1492 - accuracy: 0.9904 - val_loss: 10.1139 - val_accuracy: 0.7870\n",
            "Epoch 30/30\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.1331 - accuracy: 0.9911 - val_loss: 9.7180 - val_accuracy: 0.8110\n",
            "63/63 [==============================] - 3s 35ms/step - loss: 0.0898 - accuracy: 0.9740\n",
            "Test accuracy: 0.974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(sample_sizes, history_dict, 'bo-')\n",
        "plt.xlabel('Number of training samples')\n",
        "plt.ylabel('Test accuracy')\n",
        "plt.title('Effect of training sample size on CNN performance')\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "26lx6YLKAqxZ",
        "outputId": "b11d25d3-7e68-43af-cb64-6c72249a57a2"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_Pretrained\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
        "\n",
        "# Training has 1500 samples, test has 500 samples, and validation has 500 samples\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2500)"
      ],
      "metadata": {
        "id": "DQPLKGNnBGXN"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQmk-jHBBPC7",
        "outputId": "8d61861e-3827-4dd4-96d8-a5916d0e0ade"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function to extract features and labels\n",
        "import numpy as np\n",
        "\n",
        "def get_features_and_labels(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "# Extracting the features and labels from datasets\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
        "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels =  get_features_and_labels(test_dataset)\n",
        "train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aodS4v3BRbF",
        "outputId": "4d36d727-b978-4336-f790-d47a723dbbe1"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 1s 998ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 475ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 1s 576ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 5, 5, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xxo9ykuBnZs",
        "outputId": "38682774-5d80-4a93-f733-42d39b3aefed"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 9.4584 - accuracy: 0.9489 - val_loss: 3.8037 - val_accuracy: 0.9750\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 3.3019 - accuracy: 0.9791 - val_loss: 6.5085 - val_accuracy: 0.9650\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.9876 - accuracy: 0.9857 - val_loss: 13.8551 - val_accuracy: 0.9460\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.3396 - accuracy: 0.9907 - val_loss: 5.8428 - val_accuracy: 0.9660\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 1.1628 - accuracy: 0.9906 - val_loss: 3.1471 - val_accuracy: 0.9790\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.8689 - accuracy: 0.9921 - val_loss: 4.9840 - val_accuracy: 0.9730\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.5551 - accuracy: 0.9947 - val_loss: 4.7528 - val_accuracy: 0.9750\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.4911 - accuracy: 0.9953 - val_loss: 5.2648 - val_accuracy: 0.9740\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.5151 - accuracy: 0.9951 - val_loss: 5.0570 - val_accuracy: 0.9770\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4019 - accuracy: 0.9954 - val_loss: 5.9900 - val_accuracy: 0.9690\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.2523 - accuracy: 0.9971 - val_loss: 4.9720 - val_accuracy: 0.9770\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3063 - accuracy: 0.9969 - val_loss: 5.9966 - val_accuracy: 0.9670\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1935 - accuracy: 0.9973 - val_loss: 4.4486 - val_accuracy: 0.9770\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1534 - accuracy: 0.9981 - val_loss: 10.7993 - val_accuracy: 0.9610\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9983 - val_loss: 5.6441 - val_accuracy: 0.9760\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1649 - accuracy: 0.9980 - val_loss: 5.3794 - val_accuracy: 0.9760\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1721 - accuracy: 0.9986 - val_loss: 4.7721 - val_accuracy: 0.9770\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0207 - accuracy: 0.9996 - val_loss: 6.0880 - val_accuracy: 0.9740\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9993 - val_loss: 4.9005 - val_accuracy: 0.9780\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0988 - accuracy: 0.9981 - val_loss: 4.7932 - val_accuracy: 0.9760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQLc_leIB77s",
        "outputId": "75f481e4-8228-4752-c22c-db677af32558"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9975\n",
            "Test accuracy: 0.998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to the VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "# Freezing the layers of the pretrained CNN\n",
        "conv_base.trainable = False\n",
        "\n",
        "# UnFreezing the layers of the pretrained CNN\n",
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVLngQ7bCHnq",
        "outputId": "3f42123d-761a-495b-dda7-0ea4b62df3af"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 26\n",
            "This is the number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Declaring Data Augumentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "# Building the model and configuring it\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "SaPd2l8jCNzr"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR9mW_iqCSmK",
        "outputId": "173a6659-a812-4f45-c2a0-db0175b20b53"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "350/350 [==============================] - 19s 46ms/step - loss: 10.6124 - accuracy: 0.9264 - val_loss: 3.9107 - val_accuracy: 0.9660\n",
            "Epoch 2/50\n",
            "350/350 [==============================] - 16s 45ms/step - loss: 5.4293 - accuracy: 0.9523 - val_loss: 2.0119 - val_accuracy: 0.9810\n",
            "Epoch 3/50\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 3.5505 - accuracy: 0.9574 - val_loss: 1.6499 - val_accuracy: 0.9770\n",
            "Epoch 4/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 2.1555 - accuracy: 0.9571 - val_loss: 0.8790 - val_accuracy: 0.9810\n",
            "Epoch 5/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.2806 - accuracy: 0.9573 - val_loss: 0.6935 - val_accuracy: 0.9800\n",
            "Epoch 6/50\n",
            "350/350 [==============================] - 16s 44ms/step - loss: 1.1225 - accuracy: 0.9573 - val_loss: 0.7173 - val_accuracy: 0.9740\n",
            "Epoch 7/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.8913 - accuracy: 0.9631 - val_loss: 0.5579 - val_accuracy: 0.9770\n",
            "Epoch 8/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 0.9321 - accuracy: 0.9630 - val_loss: 0.9280 - val_accuracy: 0.9750\n",
            "Epoch 9/50\n",
            "350/350 [==============================] - 16s 45ms/step - loss: 0.9239 - accuracy: 0.9651 - val_loss: 0.8912 - val_accuracy: 0.9770\n",
            "Epoch 10/50\n",
            "350/350 [==============================] - 22s 61ms/step - loss: 0.8970 - accuracy: 0.9657 - val_loss: 0.7625 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9485 - accuracy: 0.9640 - val_loss: 1.1030 - val_accuracy: 0.9760\n",
            "Epoch 12/50\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 1.0841 - accuracy: 0.9636 - val_loss: 0.7492 - val_accuracy: 0.9800\n",
            "Epoch 13/50\n",
            "350/350 [==============================] - 16s 44ms/step - loss: 0.9126 - accuracy: 0.9694 - val_loss: 0.7725 - val_accuracy: 0.9800\n",
            "Epoch 14/50\n",
            "350/350 [==============================] - 15s 42ms/step - loss: 0.9141 - accuracy: 0.9707 - val_loss: 1.9539 - val_accuracy: 0.9690\n",
            "Epoch 15/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.0113 - accuracy: 0.9663 - val_loss: 1.2051 - val_accuracy: 0.9750\n",
            "Epoch 16/50\n",
            "350/350 [==============================] - 16s 43ms/step - loss: 0.9398 - accuracy: 0.9701 - val_loss: 1.0946 - val_accuracy: 0.9800\n",
            "Epoch 17/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.8851 - accuracy: 0.9733 - val_loss: 1.0083 - val_accuracy: 0.9790\n",
            "Epoch 18/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.9455 - accuracy: 0.9714 - val_loss: 1.0887 - val_accuracy: 0.9790\n",
            "Epoch 19/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.8455 - accuracy: 0.9731 - val_loss: 1.1530 - val_accuracy: 0.9800\n",
            "Epoch 20/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.1269 - accuracy: 0.9683 - val_loss: 1.1187 - val_accuracy: 0.9790\n",
            "Epoch 21/50\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.9870 - accuracy: 0.9704 - val_loss: 1.2575 - val_accuracy: 0.9820\n",
            "Epoch 22/50\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.8660 - accuracy: 0.9753 - val_loss: 2.0947 - val_accuracy: 0.9720\n",
            "Epoch 23/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.0654 - accuracy: 0.9713 - val_loss: 1.3755 - val_accuracy: 0.9780\n",
            "Epoch 24/50\n",
            "350/350 [==============================] - 16s 45ms/step - loss: 0.8810 - accuracy: 0.9773 - val_loss: 1.6286 - val_accuracy: 0.9760\n",
            "Epoch 25/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.0219 - accuracy: 0.9724 - val_loss: 1.1083 - val_accuracy: 0.9800\n",
            "Epoch 26/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.9966 - accuracy: 0.9726 - val_loss: 1.1156 - val_accuracy: 0.9760\n",
            "Epoch 27/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.0387 - accuracy: 0.9733 - val_loss: 2.0290 - val_accuracy: 0.9740\n",
            "Epoch 28/50\n",
            "350/350 [==============================] - 16s 45ms/step - loss: 1.0199 - accuracy: 0.9764 - val_loss: 1.0879 - val_accuracy: 0.9790\n",
            "Epoch 29/50\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.9683 - accuracy: 0.9747 - val_loss: 1.1762 - val_accuracy: 0.9790\n",
            "Epoch 30/50\n",
            "350/350 [==============================] - 23s 64ms/step - loss: 0.9939 - accuracy: 0.9753 - val_loss: 1.2670 - val_accuracy: 0.9770\n",
            "Epoch 31/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.0211 - accuracy: 0.9763 - val_loss: 1.0411 - val_accuracy: 0.9810\n",
            "Epoch 32/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.9113 - accuracy: 0.9769 - val_loss: 1.6718 - val_accuracy: 0.9760\n",
            "Epoch 33/50\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.9666 - accuracy: 0.9781 - val_loss: 1.5330 - val_accuracy: 0.9750\n",
            "Epoch 34/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.0532 - accuracy: 0.9759 - val_loss: 1.8279 - val_accuracy: 0.9760\n",
            "Epoch 35/50\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.2042 - accuracy: 0.9737 - val_loss: 1.3077 - val_accuracy: 0.9770\n",
            "Epoch 36/50\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.9788 - accuracy: 0.9756 - val_loss: 1.2255 - val_accuracy: 0.9830\n",
            "Epoch 37/50\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.0762 - accuracy: 0.9746 - val_loss: 1.7605 - val_accuracy: 0.9760\n",
            "Epoch 38/50\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 1.1054 - accuracy: 0.9750 - val_loss: 1.9115 - val_accuracy: 0.9780\n",
            "Epoch 39/50\n",
            "350/350 [==============================] - 17s 48ms/step - loss: 0.9602 - accuracy: 0.9791 - val_loss: 1.6292 - val_accuracy: 0.9800\n",
            "Epoch 40/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 0.8277 - accuracy: 0.9799 - val_loss: 3.8691 - val_accuracy: 0.9650\n",
            "Epoch 41/50\n",
            "350/350 [==============================] - 17s 47ms/step - loss: 1.1877 - accuracy: 0.9763 - val_loss: 1.7224 - val_accuracy: 0.9780\n",
            "Epoch 42/50\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 1.0212 - accuracy: 0.9769 - val_loss: 2.2706 - val_accuracy: 0.9760\n",
            "Epoch 43/50\n",
            "350/350 [==============================] - 15s 43ms/step - loss: 1.2789 - accuracy: 0.9776 - val_loss: 1.2859 - val_accuracy: 0.9770\n",
            "Epoch 44/50\n",
            "350/350 [==============================] - 17s 49ms/step - loss: 0.9371 - accuracy: 0.9771 - val_loss: 2.1657 - val_accuracy: 0.9800\n",
            "Epoch 45/50\n",
            "350/350 [==============================] - 16s 47ms/step - loss: 1.0600 - accuracy: 0.9781 - val_loss: 2.0052 - val_accuracy: 0.9800\n",
            "Epoch 46/50\n",
            "350/350 [==============================] - 19s 53ms/step - loss: 1.0566 - accuracy: 0.9784 - val_loss: 1.6087 - val_accuracy: 0.9760\n",
            "Epoch 47/50\n",
            "350/350 [==============================] - 22s 60ms/step - loss: 1.0539 - accuracy: 0.9766 - val_loss: 2.1684 - val_accuracy: 0.9770\n",
            "Epoch 48/50\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 1.1355 - accuracy: 0.9780 - val_loss: 2.7159 - val_accuracy: 0.9730\n",
            "Epoch 49/50\n",
            "350/350 [==============================] - 16s 44ms/step - loss: 1.1238 - accuracy: 0.9769 - val_loss: 1.8859 - val_accuracy: 0.9780\n",
            "Epoch 50/50\n",
            "350/350 [==============================] - 16s 44ms/step - loss: 1.1585 - accuracy: 0.9777 - val_loss: 2.0065 - val_accuracy: 0.9770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrpHYeo9FxTF",
        "outputId": "5c2c0d27-24b2-43c8-fdef-70039794975b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 74ms/step - loss: 0.2300 - accuracy: 0.9890\n",
            "Test accuracy: 0.989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedIncreasedSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)"
      ],
      "metadata": {
        "id": "xzMhJ9IDF3FO"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "# conv_base.trainable = False"
      ],
      "metadata": {
        "id": "D4wEDPAAF7tv"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using the callbacks function to monitor validation loss and running the model\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=2000)\n",
        "make_subset(\"test\", start_index=2000, end_index=3000)\n",
        "\n",
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Running the callback function to monitor validation loss\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cYFboIzF-5V",
        "outputId": "9f596cf6-20b1-492e-e3bd-bbee7e835223"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 3s 11ms/step - loss: 11.3929 - accuracy: 0.9520 - val_loss: 5.3427 - val_accuracy: 0.9660\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 3.4250 - accuracy: 0.9781 - val_loss: 15.7410 - val_accuracy: 0.9420\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 2.2616 - accuracy: 0.9846 - val_loss: 6.3649 - val_accuracy: 0.9670\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 1.3487 - accuracy: 0.9891 - val_loss: 3.7251 - val_accuracy: 0.9800\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.2111 - accuracy: 0.9901 - val_loss: 6.7381 - val_accuracy: 0.9690\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.5881 - accuracy: 0.9944 - val_loss: 4.6597 - val_accuracy: 0.9730\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.3573 - accuracy: 0.9963 - val_loss: 6.5061 - val_accuracy: 0.9740\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.9966 - val_loss: 6.2970 - val_accuracy: 0.9740\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3763 - accuracy: 0.9959 - val_loss: 4.9362 - val_accuracy: 0.9760\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4557 - accuracy: 0.9961 - val_loss: 4.9926 - val_accuracy: 0.9780\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.2787 - accuracy: 0.9971 - val_loss: 4.5598 - val_accuracy: 0.9740\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1189 - accuracy: 0.9987 - val_loss: 4.7629 - val_accuracy: 0.9780\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.9969 - val_loss: 4.7096 - val_accuracy: 0.9780\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.3600 - accuracy: 0.9969 - val_loss: 4.7289 - val_accuracy: 0.9780\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.1386 - accuracy: 0.9986 - val_loss: 5.7282 - val_accuracy: 0.9730\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1497 - accuracy: 0.9981 - val_loss: 6.2145 - val_accuracy: 0.9730\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.1045 - accuracy: 0.9986 - val_loss: 5.7132 - val_accuracy: 0.9730\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.1402 - accuracy: 0.9984 - val_loss: 4.9788 - val_accuracy: 0.9770\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1914 - accuracy: 0.9980 - val_loss: 6.1801 - val_accuracy: 0.9770\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1181 - accuracy: 0.9987 - val_loss: 7.8589 - val_accuracy: 0.9680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-FjpV9OILiY",
        "outputId": "0d903551-5704-4505-ba32-86f903c61988"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9990\n",
            "Test accuracy: 0.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating directories and assiging images to training, validation and test directories\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_PretrainedoptimalSample\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir,exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)"
      ],
      "metadata": {
        "id": "15-2TaiPIUEf"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading pre-trained weights to VGG16 model\n",
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "_SafFEnrIVVZ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "5Gr_7eA0IYcc"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Train the model with varying training sample sizes\n",
        "sample_sizes = [2500,3000,4000,5000]\n",
        "history_dict = []\n",
        "for size in sample_sizes:\n",
        "    # Set up the training subset\n",
        "    make_subset(\"temp_train\", start_index=0, end_index=size)\n",
        "    make_subset(\"validation\", start_index=size, end_index=size+500)\n",
        "    make_subset(\"test\", start_index=size+500, end_index=size+1500)\n",
        "    train_dataset = image_dataset_from_directory(\n",
        "      new_base_dir / \"temp_train\",\n",
        "      image_size=(180, 180),\n",
        "      batch_size=20)\n",
        "    # Running the callback function to monitor validation loss\n",
        "    callbacks = [\n",
        "      keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")]\n",
        "\n",
        "    # Training the model\n",
        "    history = model.fit(\n",
        "      train_features, train_labels,\n",
        "      epochs=20,\n",
        "      validation_data=(val_features, val_labels),\n",
        "      callbacks=callbacks)\n",
        "\n",
        "   # Testing the model\n",
        "    test_model = keras.models.load_model(\"feature_extraction.keras\")\n",
        "    test_loss, test_acc = test_model.evaluate(test_features, test_labels)\n",
        "    print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhuCbPFWIboY",
        "outputId": "ac5eb734-3cb2-432b-914f-4b525f81863e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 9.8640 - accuracy: 0.9499 - val_loss: 4.4913 - val_accuracy: 0.9680\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 3.3770 - accuracy: 0.9776 - val_loss: 2.2289 - val_accuracy: 0.9760\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.6591 - accuracy: 0.9849 - val_loss: 2.4760 - val_accuracy: 0.9820\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.1310 - accuracy: 0.9900 - val_loss: 5.1928 - val_accuracy: 0.9700\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.5570 - accuracy: 0.9949 - val_loss: 3.4917 - val_accuracy: 0.9730\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.7342 - accuracy: 0.9937 - val_loss: 2.5562 - val_accuracy: 0.9780\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.6342 - accuracy: 0.9931 - val_loss: 4.1850 - val_accuracy: 0.9710\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.9944 - val_loss: 3.1097 - val_accuracy: 0.9780\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.4573 - accuracy: 0.9949 - val_loss: 3.1763 - val_accuracy: 0.9810\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.2757 - accuracy: 0.9970 - val_loss: 4.1947 - val_accuracy: 0.9780\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.3543 - accuracy: 0.9960 - val_loss: 3.8949 - val_accuracy: 0.9800\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1278 - accuracy: 0.9983 - val_loss: 3.9078 - val_accuracy: 0.9760\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1848 - accuracy: 0.9980 - val_loss: 4.0199 - val_accuracy: 0.9790\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.1918 - accuracy: 0.9969 - val_loss: 3.8300 - val_accuracy: 0.9800\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.1481 - accuracy: 0.9991 - val_loss: 4.1376 - val_accuracy: 0.9800\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.2201 - accuracy: 0.9973 - val_loss: 3.8467 - val_accuracy: 0.9760\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0688 - accuracy: 0.9989 - val_loss: 3.9863 - val_accuracy: 0.9780\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1451 - accuracy: 0.9986 - val_loss: 4.8937 - val_accuracy: 0.9740\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1550 - accuracy: 0.9984 - val_loss: 3.5282 - val_accuracy: 0.9790\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.1101 - accuracy: 0.9979 - val_loss: 4.9113 - val_accuracy: 0.9770\n",
            "63/63 [==============================] - 1s 5ms/step - loss: 0.3949 - accuracy: 0.9935\n",
            "Test accuracy: 0.993\n",
            "Found 6000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9993 - val_loss: 4.0233 - val_accuracy: 0.9770\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0228 - accuracy: 0.9997 - val_loss: 3.8913 - val_accuracy: 0.9790\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0684 - accuracy: 0.9994 - val_loss: 4.2777 - val_accuracy: 0.9740\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0401 - accuracy: 0.9993 - val_loss: 4.4535 - val_accuracy: 0.9760\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0399 - accuracy: 0.9994 - val_loss: 4.6576 - val_accuracy: 0.9740\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0891 - accuracy: 0.9987 - val_loss: 4.4201 - val_accuracy: 0.9790\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.1267 - accuracy: 0.9987 - val_loss: 4.0965 - val_accuracy: 0.9780\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0572 - accuracy: 0.9990 - val_loss: 4.0884 - val_accuracy: 0.9760\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0402 - accuracy: 0.9993 - val_loss: 4.2614 - val_accuracy: 0.9780\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0641 - accuracy: 0.9993 - val_loss: 3.9148 - val_accuracy: 0.9790\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9997 - val_loss: 4.0796 - val_accuracy: 0.9800\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0750 - accuracy: 0.9991 - val_loss: 3.7527 - val_accuracy: 0.9810\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0462 - accuracy: 0.9994 - val_loss: 4.9742 - val_accuracy: 0.9760\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0296 - accuracy: 0.9994 - val_loss: 3.8619 - val_accuracy: 0.9780\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 2.5801e-09 - accuracy: 1.0000 - val_loss: 3.8764 - val_accuracy: 0.9780\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9997 - val_loss: 4.2136 - val_accuracy: 0.9800\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 1.1219e-10 - accuracy: 1.0000 - val_loss: 4.2124 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 2.0022e-07 - accuracy: 1.0000 - val_loss: 3.9680 - val_accuracy: 0.9780\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.1086e-07 - accuracy: 1.0000 - val_loss: 3.9763 - val_accuracy: 0.9770\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 6.9670e-24 - accuracy: 1.0000 - val_loss: 3.9763 - val_accuracy: 0.9770\n",
            "63/63 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.9995\n",
            "Test accuracy: 0.999\n",
            "Found 8000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9997 - val_loss: 4.0400 - val_accuracy: 0.9770\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0107 - accuracy: 0.9999 - val_loss: 4.4808 - val_accuracy: 0.9770\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 1.7550e-09 - accuracy: 1.0000 - val_loss: 4.4130 - val_accuracy: 0.9770\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9997 - val_loss: 5.0805 - val_accuracy: 0.9750\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9994 - val_loss: 4.7660 - val_accuracy: 0.9740\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9999 - val_loss: 4.1388 - val_accuracy: 0.9790\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0368 - accuracy: 0.9997 - val_loss: 4.0405 - val_accuracy: 0.9750\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0317 - accuracy: 0.9993 - val_loss: 4.4311 - val_accuracy: 0.9760\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 2.6566e-18 - accuracy: 1.0000 - val_loss: 4.4311 - val_accuracy: 0.9760\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 8.2817e-07 - accuracy: 1.0000 - val_loss: 4.5314 - val_accuracy: 0.9730\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0144 - accuracy: 0.9997 - val_loss: 4.3761 - val_accuracy: 0.9750\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 1.7083e-23 - accuracy: 1.0000 - val_loss: 4.3761 - val_accuracy: 0.9750\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0582 - accuracy: 0.9991 - val_loss: 4.2598 - val_accuracy: 0.9800\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0105 - accuracy: 0.9999 - val_loss: 4.4094 - val_accuracy: 0.9800\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0203 - accuracy: 0.9996 - val_loss: 5.5410 - val_accuracy: 0.9750\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0082 - accuracy: 0.9999 - val_loss: 4.5621 - val_accuracy: 0.9770\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0412 - accuracy: 0.9993 - val_loss: 4.6840 - val_accuracy: 0.9770\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 6.2834e-12 - accuracy: 1.0000 - val_loss: 4.6840 - val_accuracy: 0.9770\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 3.1098e-12 - accuracy: 1.0000 - val_loss: 4.6840 - val_accuracy: 0.9770\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0084 - accuracy: 0.9999 - val_loss: 5.1285 - val_accuracy: 0.9760\n",
            "63/63 [==============================] - 1s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n",
            "Found 10000 files belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 3.5332e-04 - accuracy: 0.9997 - val_loss: 5.9108 - val_accuracy: 0.9760\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 5.1597 - val_accuracy: 0.9780\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0490 - accuracy: 0.9997 - val_loss: 5.1415 - val_accuracy: 0.9800\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0139 - accuracy: 0.9997 - val_loss: 4.7080 - val_accuracy: 0.9780\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0212 - accuracy: 0.9991 - val_loss: 4.3148 - val_accuracy: 0.9780\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0060 - accuracy: 0.9997 - val_loss: 4.9111 - val_accuracy: 0.9760\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0296 - accuracy: 0.9993 - val_loss: 4.7817 - val_accuracy: 0.9780\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0408 - accuracy: 0.9994 - val_loss: 4.8609 - val_accuracy: 0.9820\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0589 - accuracy: 0.9997 - val_loss: 4.8906 - val_accuracy: 0.9820\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 4.4968 - val_accuracy: 0.9820\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 2.7220e-25 - accuracy: 1.0000 - val_loss: 4.4968 - val_accuracy: 0.9820\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0189 - accuracy: 0.9997 - val_loss: 4.4640 - val_accuracy: 0.9790\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 4.4237 - val_accuracy: 0.9790\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 5.0091 - val_accuracy: 0.9790\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 4.0496 - val_accuracy: 0.9810\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 2.2017e-12 - accuracy: 1.0000 - val_loss: 4.0496 - val_accuracy: 0.9810\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0118 - accuracy: 0.9997 - val_loss: 3.9153 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 4.9699 - val_accuracy: 0.9760\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 2.2953e-20 - accuracy: 1.0000 - val_loss: 4.9699 - val_accuracy: 0.9760\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 2s 8ms/step - loss: 3.6244e-29 - accuracy: 1.0000 - val_loss: 4.9699 - val_accuracy: 0.9760\n",
            "63/63 [==============================] - 1s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.000\n"
          ]
        }
      ]
    }
  ]
}